# **SegFormer-B2 ê²½ëŸ‰í™” í”„ë¡œì íŠ¸**

<div align="center">
    <img src="https://user-images.githubusercontent.com/113173095/217482605-77fc5273-9a6d-4e6b-bf34-89fbdf05b093.png" width=30%>
</div>

## ğŸ“° **Contributors**

**CV-16ì¡° ğŸ’¡ ë¹„ì „ê¸¸ì¡ì´ ğŸ’¡**</br>NAVER Connect Foundation boostcamp AI Tech 4th

|ë¯¼ê¸°|ë°•ë¯¼ì§€|ìœ ì˜ì¤€|ì¥ì§€í›ˆ|ìµœë™í˜|
|:----:|:----:|:----:|:---:|:---:|
|[<img alt="revanZX" src="https://avatars.githubusercontent.com/u/25689849?v=4&s=100" width="100">](https://github.com/revanZX)|[<img alt="arislid" src="https://avatars.githubusercontent.com/u/46767966?v=4&s=100" width="100">](https://github.com/arislid)|[<img alt="youngjun04" src="https://avatars.githubusercontent.com/u/113173095?v=4&s=100" width="100">](https://github.com/youngjun04)|[<img alt="FIN443" src="https://avatars.githubusercontent.com/u/70796031?v=4&s=100" width="100">](https://github.com/FIN443)|[<img alt="choipp" src="https://avatars.githubusercontent.com/u/103131249?v=4&s=117" width="100">](https://github.com/choipp)|
|Remove SelfOutput</br>Separable Attention</br>Inverted Residual Mobile Block</br>Project GitHub Management | Cross-Covariance Attention</br>Inverted Residual Mobile Block</br>ì‹¤í—˜ ê¸°ë¡ Â· ë§¤ë‰´ì–¼ ì‘ì„± ë° ê´€ë¦¬</br>Hyperparameter Tuning (Batch Size)</br>Deploy models on Jetson Nano | Weighted Sum</br>Sequence Reduction Pooling</br>ê°œì„ ëœ êµ¬ì¡° ë° ê¸°ë²• ë³‘í•©</br>Project Documentation</br>Ablation Study | Deformable Attention</br>MixCFN</br>Local Connection</br>Inference Results ì¶”ì¶œ Â· ë¶„ì„</br>Profiling Tool ì½”ë“œ ê°œì„  | PM</br>Pool Former</br>Pooling Patch Embedding</br>Learnable Resizer</br>ë ˆì´ì–´ë³„ Params Â· FLOPs ë¶„ì„|

</br>


## ğŸ“° **Links**

- [ë¹„ì „ ê¸¸ì¡ì´ Notion ğŸ“](https://vision-pathfinder.notion.site/NOTA-AI-Semantic-Segmentation-1669f7d1c9bc4f39b83ac05dd547da9b)
- [ë¹„ì „ ê¸¸ì¡ì´ ë°œí‘œìë£Œ & WrapUpReport](./appendix/)

## ğŸ“° **Objective**

>ëª¨ë¸ Params ë° FLOPs ë° ê°ê° 20% ì´ìƒ ê°ì†Œ<br/>ì„±ëŠ¥ í•˜ë½ 1% ë¯¸ë§Œìœ¼ë¡œ ìµœì†Œí™”
- **SegFormer** : ì„ë² ë””ë“œ ë° ëª¨ë°”ì¼ ê¸°ê¸°ë¥¼ ìœ„í•œ Transformer ê¸°ë°˜ Semantic Segmentation ëª¨ë¸ ê²½ëŸ‰í™”
- **Model driven approach** : í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë“± ê³ ë„í™”ëœ í•™ìŠµ ê¸°ë²• ë°°ì œ Â· ìˆœìˆ˜ ëª¨ë¸ë§ì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ
- Pruning ë° quantization ë“± **compression ë°©ë²• ë°°ì œ** : ëª¨ë¸ ë¸”ë¡ Â· ë ˆì´ì–´ ì¬ì„¤ê³„ ë“± ê²½ëŸ‰í™” êµ¬ì¡°ë³€ê²½ ì§„í–‰


## ğŸ“° **Dataset**

||Tiny-ImageNet|ADE20K|
|:----:|:---:|:---:|
||<img src="https://user-images.githubusercontent.com/113173095/217479439-5492f4b3-a115-43b7-9952-b1c1a5c850b9.png" width="200" height="200">|<img src="https://user-images.githubusercontent.com/113173095/217480114-cc9dbb9b-deaa-4620-bb78-920da8d06b84.png" width="200" height="100">|
|Purpose|Pre-training|Fine-tuning|
|Num_classes|200|150|
|Training set|100,000 images|20,210 images|
|Validation set|10,000 images|2,000 images|
<!-- ### Tiny-ImageNet (Pre-training)
<img src="https://user-images.githubusercontent.com/113173095/217479439-5492f4b3-a115-43b7-9952-b1c1a5c850b9.png" width="200" height="200">

- Num_classes : 200
- Training set : 100,000 images
- Validation set : 10,000 images
- Image Size : 64 x 64

### ADE20K (Fine-tuning)
<img src="https://user-images.githubusercontent.com/113173095/217480114-cc9dbb9b-deaa-4620-bb78-920da8d06b84.png" width="200" height="100">

- Num_classes : 150
- Training set : 20,210 images
- Validation set : 2,000 images -->

## ğŸ“° **Base Model**

![boostformer](https://user-images.githubusercontent.com/113173095/217485570-003dd0a5-6f0d-4195-8e73-c9ca64f57e02.png)
<!-- <img src="https://user-images.githubusercontent.com/113173095/217485570-003dd0a5-6f0d-4195-8e73-c9ca64f57e02.png" width="400" height="300"> -->

### Encoder

- Overlap Patch Embedding
- SegFormer Block
- Efficient Self-Attention
- Mix-FFN

### Decoder

- MLP Layer
- Concat, Linear-Fuse
- Classifier
---

## ğŸ“° **Ours Model**

![boostformer](https://user-images.githubusercontent.com/70796031/217485857-cb57f4fe-ec1d-451d-adc6-829fbecf24d9.png)

### Encoder

- **Pooling Patch Embedding**
- **PoolFormer Block**
- **SegFormerV2 Block**
- **Custom Efficient Self-Attention**
- **Mix-CFN**
### Decoder
- MLP Layer
- **Weighted Sum**
- Classifier
---

## ğŸ“° **Strategy**

- **Tiny-ImageNet Encoder pretrain** + **ADE20k fine-tuning**
    - ì»´í“¨íŒ… ìš©ëŸ‰ ì œí•œìœ¼ë¡œ ì¸í•´ Tiny-ImageNet í™œìš©
- Segformer-B2ì™€ custom model ì„±ëŠ¥ ë¹„êµ ë° Paramsì™€ Flops ì¸¡ì • (util/get_flops_params.py)

---
## ğŸ“° **Method**
### 1. Patch Embedding
<img src="https://user-images.githubusercontent.com/113173095/217486653-4cbb9082-d4a9-42ab-a131-2fb7066b2b53.png" width="250">

$F_{out}=\mathrm{Conv}(\mathrm{Pooling}_{1\times1}(F_{in}))$

### 2. Transformer Block
<img src="https://user-images.githubusercontent.com/113173095/217488041-a6efbe54-3983-4f8c-ae45-45ab9d09e859.png" height="200">

- Token Mixer : MHSA ëŒ€ì‹  Poolingìœ¼ë¡œ feature ì¶”ì¶œ
    - $\hat{F_0}=\mathrm{LayerScale}(\mathrm{Pooling}(F_{in}))+F_{in}$
    - $\hat{F_1}=\mathrm{LayerScale}(\mathrm{MixCFN}(\hat{F_0}))+\hat{F_0}$
- ê¸°ì¡´ Self Output ëª¨ë“ˆ ì‚­ì œ
    - $\hat{F_0}$
---

### 3. Attention Layer

## ğŸ“° **Result**

![result graph](https://user-images.githubusercontent.com/25689849/217489238-0ca18321-3e7a-4bd3-90aa-51bd052d1e83.svg)

| model  | Params| Flops | Acc<sub>val<sup> (%) | mIoU<sub>val<sup> (%) |
| ------------- | -------------------- | ----------------------- | ---------------------- | ----------------------- |
|SegFormer-B2|27.462M|58.576G|66.48|29.84|
|BoostFormer (Ours)|17.575M|15.826G|72.28|34.29|

## ğŸ“° **Directory Structure**

```
|-- ğŸ—‚ appendix          : ë°œí‘œìë£Œ ë° WrapUpReport
|-- ğŸ—‚ segformer         : HuggingFace ê¸°ë°˜ segformer ëª¨ë¸ ì½”ë“œ
|-- ğŸ—‚ boostformer       : Segformer ê²½ëŸ‰í™” ëª¨ë¸ ì½”ë“œ
|-- ğŸ—‚ imagenet_pretrain : Tiny-ImageNet encoder í•™ìŠµì‹œ ì‚¬ìš©í•œ ì½”ë“œ
|-- ğŸ—‚ util              : tools ì½”ë“œ ëª¨ìŒ
|-- Dockerfile
|-- train.py             : ADE20K Finetuning ì½”ë“œ
|-- eval.py              : ëª¨ë¸ Inference ê²°ê³¼ ì¶œë ¥ ì½”ë“œ
|-- requirements.txt
`-- README.md
```